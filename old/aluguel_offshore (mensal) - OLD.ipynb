{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('%s/../' % os.getcwd())\n",
    "\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from aluguel_offshore import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pasta = r'C:\\Users\\correigu\\OneDrive - Banco BTG Pactual S.A\\Desktop\\aqruivos_offshore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pasta_2 = r'C:\\Users\\correigu\\OneDrive - Banco BTG Pactual S.A\\Desktop\\relatorios_finais'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Stock Loan Fee Summary - 20180301.CSV\n",
      "Daily Stock Loan Fee Summary - 20180302.CSV\n",
      "Daily Stock Loan Fee Summary - 20180303.csv\n",
      "Daily Stock Loan Fee Summary - 20180304.csv\n",
      "Daily Stock Loan Fee Summary - 20180305.csv\n",
      "Daily Stock Loan Fee Summary - 20180306.csv\n",
      "Daily Stock Loan Fee Summary - 20180307.csv\n",
      "Daily Stock Loan Fee Summary - 20180308.csv\n",
      "Daily Stock Loan Fee Summary - 20180309.csv\n",
      "Daily Stock Loan Fee Summary - 20180310.csv\n",
      "Daily Stock Loan Fee Summary - 20180311.csv\n",
      "Daily Stock Loan Fee Summary - 20180312.csv\n",
      "Daily Stock Loan Fee Summary - 20180313.csv\n",
      "Daily Stock Loan Fee Summary - 20180314.csv\n",
      "Daily Stock Loan Fee Summary - 20180315.csv\n",
      "Daily Stock Loan Fee Summary - 20180316.csv\n",
      "Daily Stock Loan Fee Summary - 20180317.csv\n",
      "Daily Stock Loan Fee Summary - 20180318.csv\n",
      "Daily Stock Loan Fee Summary - 20180319.csv\n",
      "Daily Stock Loan Fee Summary - 20180320.csv\n",
      "Daily Stock Loan Fee Summary - 20180321.csv\n",
      "Daily Stock Loan Fee Summary - 20180322.csv\n",
      "Daily Stock Loan Fee Summary - 20180323.csv\n",
      "Daily Stock Loan Fee Summary - 20180324.csv\n",
      "Daily Stock Loan Fee Summary - 20180325.csv\n",
      "Daily Stock Loan Fee Summary - 20180326.csv\n",
      "Daily Stock Loan Fee Summary - 20180327.csv\n",
      "Daily Stock Loan Fee Summary - 20180328.csv\n",
      "Daily Stock Loan Fee Summary - 20180329.csv\n",
      "Daily Stock Loan Fee Summary - 20180330.csv\n",
      "Daily Stock Loan Fee Summary - 20180331.csv\n",
      "Daily Stock Loan Fee Summary - 20180402.csv\n",
      "Daily Stock Loan Fee Summary - 20180403.csv\n",
      "Daily Stock Loan Fee Summary - 20180404.csv\n",
      "Daily Stock Loan Fee Summary - 20180405.csv\n",
      "Daily Stock Loan Fee Summary - 20180406.csv\n",
      "Daily Stock Loan Fee Summary - 20180409.csv\n",
      "Daily Stock Loan Fee Summary - 20180410.csv\n",
      "Daily Stock Loan Fee Summary - 20180411.csv\n",
      "Daily Stock Loan Fee Summary - 20180412.csv\n",
      "Daily Stock Loan Fee Summary - 20180413.csv\n",
      "Daily Stock Loan Fee Summary - 20180416.csv\n",
      "Daily Stock Loan Fee Summary - 20180417.csv\n",
      "Daily Stock Loan Fee Summary - 20180418.csv\n",
      "Daily Stock Loan Fee Summary - 20180419.csv\n",
      "Daily Stock Loan Fee Summary - 20180420.csv\n",
      "Daily Stock Loan Fee Summary - 20180423.csv\n",
      "Daily Stock Loan Fee Summary - 20180424.csv\n",
      "Daily Stock Loan Fee Summary - 20180425.csv\n",
      "Daily Stock Loan Fee Summary - 20180426.csv\n",
      "Daily Stock Loan Fee Summary - 20180427.csv\n",
      "Daily Stock Loan Fee Summary - 20180429.CSV\n",
      "Daily Stock Loan Fee Summary - 20180430.csv\n",
      "Daily Stock Loan Fee Summary - 20180501.csv\n",
      "Daily Stock Loan Fee Summary - 20180502.csv\n",
      "Daily Stock Loan Fee Summary - 20180503.csv\n",
      "Daily Stock Loan Fee Summary - 20180504.csv\n",
      "Daily Stock Loan Fee Summary - 20180505.csv\n",
      "Daily Stock Loan Fee Summary - 20180506.csv\n",
      "Daily Stock Loan Fee Summary - 20180507.csv\n",
      "Daily Stock Loan Fee Summary - 20180508.CSV\n",
      "Daily Stock Loan Fee Summary - 20180509.CSV\n",
      "Daily Stock Loan Fee Summary - 20180510.csv\n",
      "Daily Stock Loan Fee Summary - 20180511.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 01Mar2018-64.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 01May2018-21.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 02Apr2018-42.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 02Mar2018-63.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 02May2018-20.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 03Apr2018-41.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 03May2018-19.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 04Apr2018-40.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 04May2018-18.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 05Apr2018-39.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 05Mar2018-62.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 06Apr2018-38.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 06Mar2018-61.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 07Mar2018-60.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 07May2018-17.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 08Mar2018-59.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 08May2018-16.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 09Apr2018-37.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 09Mar2018-58.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 09May2018-15.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 10Apr2018-36.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 10May2018-14.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 11Apr2018-35.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 11May2018-13.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 12Apr2018-34.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 12Mar2018-57.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 13Apr2018-33.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 13Mar2018-56.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 14Mar2018-55.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 14May2018-12.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 15Mar2018-54.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 15May2018-11.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 16Apr2018-32.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 16Mar2018-53.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 16May2018-10.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 17Apr2018-31.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 17May2018-9.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 18Apr2018-30.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 18May2018-8.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 19Apr2018-29.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 19Mar2018-52.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 20Apr2018-28.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 20Mar2018-51.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 21Mar2018-50.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 21May2018-7.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 22Mar2018-49.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 22May2018-6.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 23Apr2018-27.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 23Mar2018-48.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 23May2018-5.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 24Apr2018-26.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 24May2018-4.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 25Apr2018-25.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 25May2018-3.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 26Apr2018-24.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 26Mar2018-47.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 27Apr2018-23.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 27Mar2018-46.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 28Mar2018-45.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 28May2018-2.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 29Mar2018-44.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 29May2018-1.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 30Apr2018-22.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 30Mar2018-43.csv\n",
      "IN150DX-Financing And Domestic Contingent Access Detail Extract - 038CDF9C8 - 30May2018-0.csv\n",
      "tickers_diffs.xlsx\n"
     ]
    }
   ],
   "source": [
    "ubs, morgan, pras, bdwm, intc, ticker_diffs = ImportAluguelOffshore(pasta, pasta_2).import_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for file in os.listdir(pasta):\n",
    " \n",
    "    if 'Ajuste' in file:\n",
    "        data = file[-14:-4]\n",
    "        try:\n",
    "            ubs\n",
    "        except:\n",
    "            ubs = pd.read_csv(pasta+'\\\\'+file)\n",
    "            ubs['date']=data\n",
    "        else:\n",
    "            ubs_1 = pd.read_csv(pasta+'\\\\'+file)\n",
    "            ubs_1['date']=data\n",
    "            ubs = pd.concat([ubs,ubs_1], axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif 'PROP+ASSET' in file:\n",
    "        try:\n",
    "            pras\n",
    "        except:\n",
    "            pras = pd.read_excel(pasta+'\\\\'+file)\n",
    "            pras['date'] = pras.columns[7]\n",
    "            pras = pras.rename(columns={pras.columns[7]:'shares'})\n",
    "        else:\n",
    "            pras_1 = pd.read_excel(pasta+'\\\\'+file)\n",
    "            pras_1['date'] = pras_1.columns[7]\n",
    "            pras_1 = pras_1.rename(columns={pras_1.columns[7]:'shares'})\n",
    "            pras = pd.concat([pras,pras_1], axis=0)\n",
    "            \n",
    "            \n",
    "    \n",
    "    elif 'Aluguel INT C' in file:\n",
    "        try:\n",
    "            intc\n",
    "        except:\n",
    "            intc = pd.read_excel(pasta+'\\\\'+file)\n",
    "            intc['date'] = intc.columns[7]\n",
    "            intc = intc.rename(columns={intc.columns[7]:'shares'})\n",
    "        else:\n",
    "            intc_1 = pd.read_excel(pasta+'\\\\'+file)\n",
    "            intc_1['date'] = intc_1.columns[7]\n",
    "            intc_1 = intc_1.rename(columns={intc_1.columns[7]:'shares'})\n",
    "            intc = pd.concat([intc,intc_1], axis=0)\n",
    "    \n",
    "    elif 'Clients BD+WM' in file:\n",
    "        try:\n",
    "            bdwm\n",
    "        except:\n",
    "            bdwm = pd.read_excel(pasta+'\\\\'+file)\n",
    "            bdwm['date'] = bdwm.columns[31]\n",
    "            bdwm = bdwm.rename(columns={bdwm.columns[31]:'shares'})\n",
    "        else:\n",
    "            bdwm_1 = pd.read_excel(pasta+'\\\\'+file)\n",
    "            bdwm_1['date'] = bdwm_1.columns[31]\n",
    "            bdwm_1 = bdwm_1.rename(columns={bdwm_1.columns[31]:'shares'})\n",
    "            bdwm = pd.concat([bdwm,bdwm_1], axis=0)\n",
    "            #print (str(bdwm_1.shape)+' ------ '+str(bdwm.shape))\n",
    "    \n",
    "    elif ('038CDBD08_IN150DX' in file)|('038CDB895_IN150DX' in file):\n",
    "        try:\n",
    "            morgan\n",
    "        except:\n",
    "            morgan = pd.read_csv(pasta+'\\\\'+file, skipfooter=1, engine='python')\n",
    "        else:\n",
    "            morgan_1 = pd.read_csv(pasta+'\\\\'+file, skipfooter=1, engine='python')\n",
    "            morgan = pd.concat([morgan, morgan_1], axis = 0)\n",
    "        \n",
    "    else:\n",
    "        print (file)\n",
    "\n",
    "\n",
    "ticker_diffs = pd.read_excel(pasta+'\\\\'+ 'tickers_diffs.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "months_dict = {\n",
    "    1:'jan',\n",
    "    2:'fev',\n",
    "    3:'mar',\n",
    "    4:'abr',\n",
    "    5:'mai',\n",
    "    6:'jun',\n",
    "    7:'jul',\n",
    "    8:'ago',\n",
    "    9:'set',\n",
    "    10:'out',\n",
    "    11:'nov',\n",
    "    12:'dez'\n",
    "}\n",
    "\n",
    "def ajuste_ubs(ubs):\n",
    "    \n",
    "    ubs['date'] = pd.to_datetime(ubs['date'], format='%Y-%m-%d')\n",
    "    ubs['date'] = np.where(ubs['date'].dt.weekday==6, ubs['date']-datetime.timedelta(2), ubs['date'])\n",
    "    ubs['Daily Accrual'] = ((ubs['Daily Accrual'].str.replace('\\(', '-')).str.replace('\\)', '')).astype(float).copy()\n",
    "    \n",
    "    \n",
    "    ubs['pb'] = 'ubs'\n",
    "    ubs['month_number'] = ubs['date'].dt.month\n",
    "    ubs['year'] = ubs['date'].dt.year\n",
    "    ubs['month']=ubs['month_number'].apply(lambda x: months_dict[x]).copy()\n",
    "    \n",
    "    ubs['cusip'] = np.nan\n",
    "    ubs = ubs[['Reference Account Id' ,'pb', 'date', 'Ticker', 'ISIN', 'cusip', 'Quantity',\n",
    "               'Daily Accrual', 'Billing CCY', 'month', 'year']].drop_duplicates().reset_index(drop=True)\n",
    "    ubs.columns = ['conta', 'pb', 'data_ref', 'ticker', 'isin', 'cusip', 'qt', 'accrual', 'currency', 'month', 'year']\n",
    "    ubs = ubs.drop_duplicates(subset=['conta', 'data_ref', 'ticker', 'qt', 'currency']).reset_index(drop=True)    \n",
    "    return ubs\n",
    "\n",
    "def ajuste_calypso(pras, bdwm, intc):\n",
    "    pras['tipo'] = 'ASSET'\n",
    "    bdwm['tipo'] = 'WM'\n",
    "    intc['tipo'] = 'INT C'\n",
    "\n",
    "    calypso = pd.concat([pras, bdwm, intc], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    calypso['date'] = pd.to_datetime(calypso['date'])\n",
    "    calypso['month_number'] = calypso['date'].dt.month\n",
    "    calypso['year'] = calypso['date'].dt.year\n",
    "    calypso['month']=calypso['month_number'].apply(lambda x: months_dict[x])\n",
    "\n",
    "    calypso = calypso[['Account Name','tipo', 'Agent','date', 'shares', 'Book', 'PRODUCT_CODE.TICKER', 'PRODUCT_CODE.ISIN', \n",
    "                       'PRODUCT_CODE.CUSIP', 'Product Currency', 'month', 'year']].reset_index(drop=True)\n",
    "    calypso.columns = ['conta_pb','conta', 'agent', 'data_ref', 'quantidade', 'book', 'ticker', 'isin', 'cusip', \\\n",
    "                       'currency', 'month', 'year']\n",
    "    return calypso\n",
    "\n",
    "\n",
    "def ajuste_morgan(morgan):\n",
    "    morgan['date'] = pd.to_datetime(morgan['Value Date'], errors='coerce', format = '%m/%d/%Y')\n",
    "\n",
    "    morgan['pb'] = 'ms'\n",
    "    morgan['month_number'] = morgan['date'].dt.month\n",
    "    morgan['year'] = morgan['date'].dt.year\n",
    "    morgan['month']=morgan['month_number'].apply(lambda x: months_dict[x])\n",
    "\n",
    "    morgan = morgan[['Account', 'pb', 'date', 'Symbol', 'ISIN', 'Cusip', 'Shares', 'Net Borrow Cost', 'Currency', 'month', 'year']] \n",
    "\n",
    "    morgan.columns = ['conta', 'pb', 'data_ref', 'ticker', 'isin', 'cusip', 'qt', 'accrual', 'currency', 'month', 'year']\n",
    "    \n",
    "    morgan['data_ref'] = np.where(morgan['data_ref'].dt.weekday==6, morgan['data_ref']-datetime.timedelta(2), morgan['data_ref'])\n",
    "    morgan = morgan.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    return morgan\n",
    "\n",
    "def get_pb(morgan, ubs):\n",
    "    ubs = ajuste_ubs(ubs)\n",
    "    morgan = ajuste_morgan(morgan)\n",
    "    \n",
    "    pb = pd.concat([morgan, ubs], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    pb.qt = (pb.qt.replace( '[)]','', regex=True )\n",
    "               .replace( '[(]','-',   regex=True ).astype(float))\n",
    "    \n",
    "    \n",
    "    return pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustes base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb = get_pb(morgan, ubs)\n",
    "calypso = ajuste_calypso(pras, bdwm, intc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calypso = calypso[calypso.conta_pb.isin(pb.conta.drop_duplicates())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb = pb[pb.data_ref.dt.weekday<5]\n",
    "calypso = calypso[calypso.data_ref.dt.weekday<5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb['accrual_adjusted'] = np.where(pb.data_ref.dt.weekday==4, pb['accrual']*3, pb['accrual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coloca a soma por dia e por ticker na tabela do calypso original (que está dividida por book)\n",
    "'''tickers_calypso = calypso.groupby(by=['data_ref', 'ticker']).sum()\n",
    "tickers_calypso = tickers_calypso.reset_index().drop('year', axis=1)\n",
    "calypso = pd.merge(calypso, tickers_calypso, on=['data_ref', 'ticker'], how='left')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dict_contas = {\n",
    "    '038CDB895':'int_c',\n",
    "    '038CDBD08':'ms_cayman',\n",
    "    75201835:'ubs_cayman',\n",
    "    75202213:'ubs_cayman',\n",
    "    75202215:'ubs_cayman'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb['acc'] = pb['conta'].apply(lambda x: dict_contas[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers_calypso = calypso[['ticker', 'isin', 'cusip']].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers_pb = pb[['ticker', 'isin', 'cusip']].drop_duplicates().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_isin = pd.merge(tickers_calypso, tickers_pb[tickers_pb['isin'].isnull()==False], on='isin', how='left').drop(['cusip_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "on_isin.columns = ['ticker_calypso', 'isin', 'cusip', 'ticker_byisin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "on_cusip = pd.merge(on_isin,  tickers_pb[tickers_pb['cusip'].isnull()==False], on=['cusip'], how = 'left').drop('isin_y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_cusip['ticker_pb'] = np.where(on_cusip['ticker_byisin'].isnull()==False, on_cusip['ticker_byisin'], on_cusip['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mapa_tickers = on_cusip[['ticker_calypso', 'ticker_pb']].dropna().reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mapa_tickers = mapa_tickers[['ticker_pb', 'ticker_calypso']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapa_dict = mapa_tickers.set_index('ticker_pb')['ticker_calypso'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mapeamento(mapa_dict, x):\n",
    "    try:\n",
    "        mapa_dict[x]\n",
    "    except:\n",
    "        mapa = np.nan\n",
    "    else:\n",
    "        mapa = mapa_dict[x]\n",
    "    \n",
    "    return mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb['ticker_ajuste'] = pb['ticker'].apply(lambda x: mapeamento(mapa_dict, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb[pb['ticker_ajuste'].isnull()==True]['ticker'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_ajustes = {\n",
    "    'DHT':'DHT US',\n",
    "    'GOLD':'GOLD US',\n",
    "    'SIG':'SIG US',\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calypso[calypso['ticker'].str.contains('SIG')==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb = pb.merge(mapa_tickers, left_on = 'ticker', right_on='ticker_pb', how='left').drop('ticker_pb', axis=1).rename(columns={\n",
    "    'ticker':'ticker_original_pb',\n",
    "    'ticker_calypso':'ticker'\n",
    "})[['conta', 'pb', 'data_ref', 'ticker', 'isin', 'cusip', 'qt', 'accrual',\n",
    "       'currency', 'month', 'year', 'accrual_adjusted', 'acc', 'ticker_original_pb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batimento mensal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calypso = calypso[((calypso.month=='mar')|(calypso.month=='abr'))&(calypso.year==2018)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb = pb[((pb.month=='mar')|(pb.month=='abr'))&(pb.year==2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calypso = pd.merge(calypso, calypso.groupby(by=['conta_pb', 'agent', 'data_ref', 'ticker']).sum().reset_index(), \n",
    "         on = ['conta_pb', 'agent', 'data_ref', 'ticker']).drop('year_y', axis=1).rename(columns = {\n",
    "    'quantidade_x':'quantidade_book',\n",
    "    'quantidade_y':'quantidade_ticker',\n",
    "    'year_x':'year',\n",
    "    'conta':'tipo',\n",
    "    'conta_pb':'conta',\n",
    "    'agent':'pb'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calypso['pb'] = calypso['pb'].replace('MORGAN STANLEY & CO', 'ms').replace('UBS SECURITIES LLC', 'ubs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb['id'] = range(1, pb.shape[0] +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento = pd.merge(calypso, pb, on=['conta', 'pb', 'data_ref','ticker', 'currency'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nova tentativa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento = batimento.drop(['isin_y', 'cusip_y', 'month_y', 'year_y'], axis=1).rename(columns={\n",
    "    'isin_x':'isin',\n",
    "    'cusip_x':'cusip',\n",
    "    'month_x':'month',\n",
    "    'year_x':'year'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento = batimento[['conta', 'tipo', 'pb', 'data_ref','ticker','book', 'quantidade_book', 'quantidade_ticker', 'qt',\n",
    "       'accrual', 'accrual_adjusted', 'acc', 'currency','isin', 'cusip', 'month', 'year', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento['qt'] = -1*batimento['qt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento = batimento[batimento['qt'].isnull()==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batidos = batimento[abs(batimento['quantidade_ticker'])==abs(batimento['qt'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos_in_tickers_diff = batimento[(batimento['isin'].isin(ticker_diffs['Isin']))\\\n",
    "                                      &(abs(batimento.qt)!=abs(batimento.quantidade_ticker))&\\\n",
    "                                         (batimento.pb=='ms')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos_in_tickers_diff['quantidade_ticker']=n_batidos_in_tickers_diff.qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos = batimento[(abs(batimento.qt)!=abs(batimento['quantidade_ticker']))&~((batimento['isin'].isin(ticker_diffs['Isin']))\\\n",
    "                                                          &(batimento.pb=='ms'))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos['check'] = abs(n_batidos.qt/n_batidos.quantidade_ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percent = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos_aceitavel = n_batidos[((n_batidos.check<(1+percent))&(n_batidos.check>(1-percent)))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos_diff_grande = n_batidos[~((n_batidos.check<(1+percent))&(n_batidos.check>(1-percent)))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_batidos_aceitavel['quantidade_ticker']=n_batidos_aceitavel.qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check de tamanhos\n",
    "(batidos.shape[0]+n_batidos_in_tickers_diff.shape[0]+n_batidos_aceitavel.shape[0] + \\\n",
    "                             n_batidos_diff_grande.shape[0])/batimento.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(batidos.shape[0]+n_batidos_in_tickers_diff.shape[0]+n_batidos_aceitavel.shape[0])\\\n",
    "                             /batimento.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "already_in = batimento['id'].drop_duplicates().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_in = pb[pb['id'].isin(already_in)==False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_in.shape[0]/pb.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_in.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_in['conta'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_in[(not_in.data_ref==pd.to_datetime('2018-03-07'))&(not_in.ticker=='EWZ US')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calypso[(calypso.data_ref==pd.to_datetime('2018-03-07'))&(calypso.ticker.str.contains('EWZ'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste por ticker (março 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mar_pb = pb[(pb.month=='mar')&(pb.year==2018)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mar_calypso = calypso[(calypso.month=='mar')&(calypso.year==2018)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_byticker_pb = mar_pb.groupby(by=['ticker', 'currency']).sum().reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_byticker_calypso = mar_calypso.groupby(by=['ticker', 'currency']).sum().reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_byticker_calypso['ticker'] = check_byticker_calypso['ticker'].str.split().str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_tickers = pd.merge(check_byticker_pb, check_byticker_calypso, on = ['ticker', 'currency'], how='left')\\\n",
    "                    .drop(['year_x', 'year_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_tickers = check_tickers[['ticker', 'currency', 'accrual', 'qt', 'quantidade']]\n",
    "check_tickers.columns = ['ticker', 'currency', 'accrual', 'qt_pb', 'qt_calypso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_tickers['accrual'] = np.where(check_tickers['accrual']==0, np.nan, check_tickers['accrual'])\n",
    "check_tickers['qt_pb'] = np.where(check_tickers['qt_pb']==0, np.nan, check_tickers['qt_pb'])\n",
    "check_tickers['qt_calypso'] = np.where(check_tickers['qt_calypso']==0, np.nan, check_tickers['qt_calypso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_tickers['diff_total'] = check_tickers.qt_pb-check_tickers.qt_calypso\n",
    "check_tickers['diff_pct'] = check_tickers.qt_pb/check_tickers.qt_calypso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batido = check_tickers[(check_tickers.diff_pct==-1)|(check_tickers.diff_pct==1)].reset_index(drop=True)\n",
    "batido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "on_pb_off_calypso = check_tickers[pd.isnull(check_tickers['qt_calypso'])==True].reset_index(drop=True)\n",
    "on_pb_off_calypso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_batido = check_tickers[(check_tickers.diff_pct<-1)|(check_tickers.diff_pct>1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_batido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_batido[not_batido['ticker'].isin(ticker_diffs.Stock)==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_batido[not_batido['ticker'].isin(ticker_diffs.Stock)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calypso['check_dia'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calypso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb['check_dia'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pb.conta.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvt_1 = pd.pivot_table(pb, values=['check_dia'],\n",
    "                     index='data_ref', columns=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pvt_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvt = pd.pivot_table(calypso, values=['check_dia'],\n",
    "                     index='data_ref', columns=['tipo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste = ajuste_calypso(pras, bdwm, intc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "morgan = ajuste_morgan(morgan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wm = morgan[morgan['conta']=='038CDF9C8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wm['month'] = wm.data_ref.dt.month\n",
    "wm['year'] = wm.data_ref.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wm.groupby(by=['year','month', 'currency']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
